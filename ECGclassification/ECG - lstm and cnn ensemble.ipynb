{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n!pip install torchsummary\nfrom torchsummary import summary\nfrom sklearn.preprocessing import OneHotEncoder\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/mitbih_train.csv\", header=None)\ndf2 = pd.read_csv(\"../input/mitbih_test.csv\", header=None)\ndf = pd.concat([df, df2], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.iloc[:,:-1].values\ny = df.iloc[:,187:188].values.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"C0 = np.argwhere(y == 0).flatten()\nC1 = np.argwhere(y == 1).flatten()\nC2 = np.argwhere(y == 2).flatten()\nC3 = np.argwhere(y == 3).flatten()\nC4 = np.argwhere(y == 4).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = np.arange(0, 187)*8/1000\n\nplt.figure(figsize=(20,12))\n\nplt.plot(X, x[C0, :][0], label=\"Cat. N\")\nplt.plot(X, x[C1, :][0], label=\"Cat. S\")\nplt.plot(X, x[C2, :][0], label=\"Cat. V\")\nplt.plot(X, x[C3, :][0], label=\"Cat. F\")\nplt.plot(X, x[C4, :][0], label=\"Cat. Q\")\nplt.legend()\nplt.title(\"1-beat ECG for every category\", fontsize=20)\nplt.ylabel(\"Amplitude\", fontsize=15)\nplt.xlabel(\"Time (ms)\", fontsize=15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def stretch(x):\n    l = int(187 * (1 + (random.random()-0.5)/3))\n    y = resample(x, l)\n    if l < 187:\n        y_ = np.zeros(shape=(187, ))\n        y_[:l] = y\n    else:\n        y_ = y[:187]\n    return y_\n\ndef amplify(x):\n    alpha = (random.random()-0.5)\n    factor = -alpha*x + (1+alpha)\n    return x*factor\n\ndef augment(x):\n    result = np.zeros(shape= (4, 187))\n    for i in range(3):\n        if random.random() < 0.33:\n            new_y = stretch(x)\n        elif random.random() < 0.66:\n            new_y = amplify(x)\n        else:\n            new_y = stretch(x)\n            new_y = amplify(new_y)\n        result[i, :] = new_y\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.signal import resample\nresult = np.apply_along_axis(augment, axis=1, arr=x[C3]).reshape(-1, 187)\nclasse = np.ones(shape=(result.shape[0],), dtype=int)*3\nclasse = np.reshape(classe,(6424,1))\nx = np.vstack([x, result])\ny = np.vstack([y, classe])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test =  train_test_split(x, y, test_size=0.2, random_state=42)\n'''ohe = OneHotEncoder(categorical_features = [0])\ny_train = ohe.fit_transform(y_train.reshape(-1,1)).toarray()\ny_test = ohe.transform(y_test.reshape(-1,1)).toarray()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nimport torch\nfrom torch import nn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self,x,y):\n        (n,f) = x.shape\n        self.x = np.reshape(x,(n,1,f))\n        self.y = y\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self,idx):\n        return torch.from_numpy(self.x[idx]),int(self.y[idx])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = dataset(X_train,y_train)\ntrain_loader = DataLoader(train_data, batch_size=1000)\ntest_data = dataset(X_test,y_test)\ntest_loader = DataLoader(test_data, batch_size=1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model 1 cnn\nclass conv_model(nn.Module):\n    def __init__(self):\n        super(conv_model, self).__init__()\n        self.c1 = nn.Conv1d(in_channels = 1, out_channels = 32, kernel_size = 5, stride=1)\n        self.c2 = nn.Conv1d(in_channels = 32, out_channels = 32, kernel_size = 5, stride=1)\n        self.maxpool = nn.MaxPool1d(kernel_size = 5, stride = 2)\n        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=False)\n        self.linear1 = nn.Linear(4896,32)\n        self.linear2 = nn.Linear(32,5)\n        self.softmax = nn.LogSoftmax(dim = 1)\n        self.dropout = nn.Dropout(p = 0.3)\n    def forward(self, input):\n        \n        C = self.c1(input)\n        C11 = self.c2(C)\n        A11 = self.relu(C11)\n        C12 = self.c2(A11)\n        S11 = torch.cat((C12,C), dim = 2)\n        A12 = self.relu(S11)\n        M11 =  self.dropout(self.maxpool(A12))\n        \n        C21 = self.c2(M11)\n        A21 = self.relu(C21)\n        C22 = self.c2(A21)\n        S21 = torch.cat((C22,M11), dim = 2)\n        A22 = self.relu(S21)\n        M21 =  self.dropout(self.maxpool(A22))\n        \n        C31 = self.c2(M21)\n        A31 = self.relu(C31)\n        C32 = self.c2(A31)\n        S31 = torch.cat((C32,M21), dim = 2)\n        A32 = self.relu(S31)\n        M31 =  self.dropout(self.maxpool(A32))\n        \n        C41 = self.c2(M31)\n        A41 = self.relu(C41)\n        C42 = self.c2(A41)\n        S41 = torch.cat((C42,M31), dim = 2)\n        A42 = self.relu(S41)\n        M41 = self.maxpool(A42)\n        \n        C51 = self.c2(M41)\n        A51 = self.relu(C51)\n        C52 = self.c2(A51)\n        S51 = torch.cat((C52,M41), dim = 2)\n        A52 = self.relu(S51)\n        M51 =  self.maxpool(A52)\n        \n        F1 = M51.view(M51.size(0),-1)\n        \n        D1 = self.relu(self.linear1(F1))\n        output = self.softmax(self.linear2(D1))\n        return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = conv_model().to('cuda')\nsummary(model,(1,187))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n# Loss -> Negative log likelihood loss\ncriterion = nn.NLLLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(classifier,epoch,dataloader,batch_size,training = True , valid_loader = None):\n    losses = []\n    accuracy = []\n    lr = 0.001\n    if(training == False):\n        epoch = 1\n    for i in range(epoch):\n        j=0\n        running_corrects = 0\n        running_loss=0\n        optimizer = optim.Adam(classifier.parameters(), lr=lr)\n        if(epoch%3==0):\n            lr = lr/2\n        if(epoch%20==0):\n            lr = 0.001\n        for batch_idx, (data, target) in enumerate(dataloader):\n            if(training == False):\n                classifier.eval()\n            else:\n                classifier.train()\n            data, target = Variable(data), Variable(target)\n            data = data.type(torch.cuda.FloatTensor)\n            target = target.type(torch.cuda.LongTensor)\n            optimizer.zero_grad()\n            output = classifier(data)\n            loss = criterion(output, target)\n            if(training==True):\n                loss.backward()\n                optimizer.step()\n            _, preds = torch.max(output, 1)\n            running_corrects = running_corrects + torch.sum(preds == target.data)\n            running_loss += loss.item() * data.size(0)\n            j = j+1\n            if(training == True):\n                if batch_idx % 10 == 0:\n                    print('Train Epoch: {}  [{}/{} ({:.0f}%)]\\tLoss: {:.6f} \\tAcc: {:.6f}'.format(i, batch_idx * len(data), len(dataloader.dataset),100. * batch_idx / len(dataloader)\n                                                                                             , running_loss/(j*1000),running_corrects.double()/(j*1000)))\n        epoch_acc = running_corrects.double()/(len(dataloader)*batch_size)\n        epoch_loss = running_loss/(len(dataloader)*batch_size)\n        print('Acc {} Loss {}'.format(epoch_acc.item(),epoch_loss))\n        losses.append(epoch_loss)\n        accuracy.append(epoch_acc)\n        if(valid_loader != None):\n            train(classifier,1,valid_loader,1000 , training = False)\n    return losses,accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss1,accuracy1 = train(model,75,train_loader,1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model 1 cnn\nclass lstm_model(nn.Module):\n    def __init__(self):\n        super(lstm_model, self).__init__()\n        self.lstm = nn.GRU(187,400,3)\n        self.softmax = nn.LogSoftmax(dim = 1)\n        self.linear1 = nn.Linear(400,100)\n        self.relu = nn.LeakyReLU(negative_slope=0.1, inplace=False)\n        self.linear2 = nn.Linear(100,5)\n    def forward(self, input):\n        output,_ = self.lstm(input)\n        output = output.view(output.size(0),-1)\n        x = self.relu(self.linear1(output))\n        x = self.softmax(self.linear2(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = lstm_model().to('cuda')\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = nn.LSTM(187,100,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss1,accuracy1 = train(model1,20,train_loader,1000 , valid_loader = test_loader)\n#loss1,accuracy1 = train(model1,1,test_loader,1000,train = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input = torch.randn(1000, 1, 187)\ninput = input.to('cuda')\noutput = model(input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input = torch.randn(1000, 1, 187)\no,(h,c) = model2(input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o.shape","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}